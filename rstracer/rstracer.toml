# Configuration File for rstracer

# If a rstracer.toml exists in the workspace, the programs will use it, else a default configuration will be applied.

# If set to true, the database is stored in memory ("in-memory" mode), which offers higher performance,
# but the data is not accessible outside the running process. Use this mode only if you are using
# rstracer as a library. If set to false, the database is stored in a file named "rstracer.db".
# This option is less performant but allows querying the file after the process ends.
in_memory = false

# [Vacuum Task]
# The vacuum task deletes rows from tables where data insertion is older than X seconds.
# There is a trade-off between keeping historical data and maintaining performance. Larger tables
# can lead to slower query times. For bronze and silver layers, we recommend maintaining a short
# retention period, as gold tables should be the primary target for querying.
# Note: In "in-memory" mode, retaining large amounts of data can lead to memory issues.
# Set a value of 0 to disable vacuum for a specific layer.
[vacuum]
bronze = 15   # Retention period in seconds for bronze layer
silver = 15   # Retention period in seconds for silver layer
gold = 600    # Retention period in seconds for gold layer

# [Scheduling Tasks]
# Once data from the `ps`, `lsof`, and network packet commands is inserted into the bronze layer,
# scheduled tasks are executed periodically for silver, gold, vacuum, and dimension tasks.
# - **Silver**: Extracts, transforms, and loads (ETL) data from the bronze layer.
# - **Gold**: ETL process from the silver layer.
# - **Vacuum**: Executes the vacuum tasks as defined above.
# - **Dimension**: Dimension tables contain auxiliary information such as data from `/etc/hosts` or `/etc/services`.
#   They are loaded at the beginning of the run and donâ€™t need regular updates.
[schedule]
silver = 5        # Frequency in seconds to run the silver task
gold = 5          # Frequency in seconds to run the gold task
vacuum = 15       # Frequency in seconds to run the vacuum task
dimension = 300   # Frequency in seconds to run the dimension task

# [Request Channel]
# DuckDB does not allow concurrent writes. All requests are queued in a channel, which is processed sequentially
# by a dedicated thread. The following configuration defines the behavior of this channel:
# - `channel_size`: The maximum number of requests stored in the queue. A value higher than 100 is not recommended.
# - If the channel is often full, consider decreasing input frequencies (like for `ps` or `lsof`) or
#   decreasing schedule task frequencies (such as silver or gold).
# - `consumer_batch_size`: Number of requests executed in a single DuckDB batch.
[request]
channel_size = 100           # Maximum number of requests in the queue
consumer_batch_size = 20     # Number of requests executed per batch

# [Process Monitor (`ps` command)]
# The `ps` command lists active processes.
# - `producer_frequency`: The number of seconds to wait between two `ps` command executions.
# - `consumer_batch_size`: Number of rows per batch in the `VALUES` section of an `INSERT INTO` statement.
#   A value around 200 is recommended.
[ps]
producer_frequency = 3       # Time interval (in seconds) between consecutive executions of `ps`
consumer_batch_size = 200    # Rows per batch in the `INSERT INTO` statements

# [File Monitor (`lsof` command)]
# The `lsof` command lists all open files. We filter results to include only network and regular files.
# - `producer_frequency`: The number of seconds between two executions of `lsof`.
# - `consumer_batch_size`: Number of rows per batch in the `VALUES` section of an `INSERT INTO` statement.
#   A value around 200 is recommended.
[lsof]
producer_frequency = 15      # Time interval (in seconds) between consecutive executions of `lsof`
consumer_batch_size = 200    # Rows per batch in the `INSERT INTO` statements

# [Network Packet Capture]
# A thread listens to all open interfaces and writes full packet objects to a queue. Another thread
# reads this queue and splits each packet into requests for different tables (ethernet, ipv4, etc.).
# - `channel_size`: Maximum size of the packet queue.
# - `producer_frequency`: Number of seconds between consecutive queue reads.
# - `consumer_batch_size`: Number of packets read per batch.
[network]
channel_size = 500           # Maximum number of packets in the queue
producer_frequency = 1       # Time interval (in seconds) between consecutive reads from the queue
consumer_batch_size = 200    # Packets read per batch